from dataclasses import dataclass
from typing import List, Dict, Any, Optional
from pathlib import Path
from datetime import timezone
import io
import os

from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib import colors
import matplotlib.pyplot as plt

from config import config as AppConfig


@dataclass
class Chart:
    title: str
    image_bytes: bytes


class ReportGenerator:
    def __init__(self, template_path: str = None):
        self.template_path = template_path or str(AppConfig.PDF_TEMPLATE_PATH)
        os.makedirs(AppConfig.CHART_CACHE_DIR, exist_ok=True)

    def generate_text_summary(self, analysis: Dict[str, Any]) -> str:
        parts: List[str] = []
        parts.append(f"–°–∏–º–≤–æ–ª: {analysis['symbol']}")
        parts.append(f"–¢–∞–π–º—Ñ—Ä–µ–π–º: {analysis.get('timeframe', '1day')}")
        parts.append(f"–ò—Ç–æ–≥–æ–≤—ã–π —Å–∫–æ—Ä: {analysis['overall_score']:.2f}, —Ä–∏—Å–∫: {analysis['risk_level']}, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {analysis['recommendation']}")
        parts.append(f"–ö–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã: {', '.join(analysis.get('key_points', []))}")
        parts.append("\n" + analysis.get('disclaimer', ''))
        return "\n".join(parts)

    def generate_detailed_text_report(self, analysis: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        parts: List[str] = []
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        parts.append(f"üöÄ <b>–†–ê–°–®–ò–†–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó {analysis['symbol']}</b>")
        parts.append("=" * 50)
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        parts.append(f"\nüìä <b>–û–°–ù–û–í–ù–´–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò</b>")
        parts.append(f"‚Ä¢ –°–∏–º–≤–æ–ª: {analysis['symbol']}")
        parts.append(f"‚Ä¢ –¢–∞–π–º—Ñ—Ä–µ–π–º: {analysis.get('timeframe', '1day')} (–¥–Ω–µ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)")
        parts.append(f"‚Ä¢ –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {analysis.get('timestamp', 'N/A')}")
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        if 'technical' in analysis:
            tech = analysis['technical']
            parts.append(f"\nüìà <b>–¢–ï–•–ù–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó</b>")
            parts.append(f"‚Ä¢ –¢—Ä–µ–Ω–¥: {tech.get('trend', 'N/A')}")
            if 'moving_averages' in tech:
                ma = tech['moving_averages']
                parts.append(f"‚Ä¢ MA7: {ma.get('MA7', 0):.2f}")
                parts.append(f"‚Ä¢ MA30: {ma.get('MA30', 0):.2f}")
        
        # –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
        if 'sentiment' in analysis:
            sent = analysis['sentiment']
            parts.append(f"\nüì∞ <b>–ê–ù–ê–õ–ò–ó –ù–ê–°–¢–†–û–ï–ù–ò–ô</b>")
            if 'overall' in sent:
                overall = sent['overall']
                parts.append(f"‚Ä¢ –û–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {overall.get('label', 'N/A')} ({overall.get('score', 0):.2f})")
            if 'key_themes' in sent:
                themes = sent['key_themes']
                if themes:
                    parts.append(f"‚Ä¢ –ö–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã: {', '.join(themes[:5])}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        parts.append(f"\nüí° <b>–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò</b>")
        parts.append(f"‚Ä¢ –û–±—â–∏–π —Å–∫–æ—Ä: {analysis.get('overall_score', 0):.2f}/1.0")
        parts.append(f"‚Ä¢ –£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: {analysis.get('risk_level', 'N/A')}")
        parts.append(f"‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {analysis.get('recommendation', 'N/A').upper()}")
        
        # –ö–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã
        if 'key_points' in analysis and analysis['key_points']:
            parts.append(f"\nüîë <b>–ö–õ–Æ–ß–ï–í–´–ï –ú–û–ú–ï–ù–¢–´</b>")
            for i, point in enumerate(analysis['key_points'][:5], 1):
                parts.append(f"{i}. {point}")
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        if 'data_sources' in analysis:
            parts.append(f"\nüìã <b>–ò–°–¢–û–ß–ù–ò–ö–ò –î–ê–ù–ù–´–•</b>")
            parts.append(f"‚Ä¢ {', '.join(analysis['data_sources'])}")
        
        # –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if 'confidence_level' in analysis:
            parts.append(f"\nüéØ <b>–£–†–û–í–ï–ù–¨ –£–í–ï–†–ï–ù–ù–û–°–¢–ò</b>")
            parts.append(f"‚Ä¢ {analysis['confidence_level']:.1%}")
        
        # –î–∏—Å–∫–ª–µ–π–º–µ—Ä
        parts.append(f"\n‚ö†Ô∏è <b>–í–ê–ñ–ù–û</b>")
        parts.append("‚Ä¢ –ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –¥–Ω–µ–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç—è—Ö")
        parts.append("‚Ä¢ –ù–µ —è–≤–ª—è–µ—Ç—Å—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π")
        parts.append("‚Ä¢ –ü—Ä–æ–≤–æ–¥–∏—Ç–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º")
        
        return "\n".join(parts)

    def generate_readable_report_from_template(self, analysis: Dict[str, Any], market_data=None) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —á–∏—Ç–∞–µ–º—ã–π –æ—Ç—á–µ—Ç –∏–∑ —à–∞–±–ª–æ–Ω–∞ markdown
        
        Args:
            analysis: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –∞–Ω–∞–ª–∏–∑–∞
            market_data: DataFrame —Å —Ä—ã–Ω–æ—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –ó–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –≤ –≤–∏–¥–µ —Ç–µ–∫—Å—Ç–∞ (markdown)
        """
        from datetime import datetime
        import pandas as pd
        
        # –ß–∏—Ç–∞–µ–º —à–∞–±–ª–æ–Ω
        template_path = Path(self.template_path) / "–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∞.md"
        if not template_path.exists():
            # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø—É—Ç—å
            template_path = Path(__file__).parent.parent / "templates" / "–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∞.md"
        
        if not template_path.exists():
            return "‚ùå –®–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω"
        
        try:
            with open(template_path, 'r', encoding='utf-8') as f:
                template = f.read()
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —à–∞–±–ª–æ–Ω–∞: {e}"
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–º–µ–Ω—ã
        symbol = analysis.get('symbol', 'N/A')
        sentiment = analysis.get('sentiment', {})
        overall_sentiment = sentiment.get('overall', {})
        technical = analysis.get('technical', {})
        ma = technical.get('moving_averages', {})
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É –∏–∑ market_data –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
        current_price = 'N/A'
        if market_data is not None and not market_data.empty:
            try:
                if 'close' in market_data.columns:
                    current_price = f"${market_data['close'].iloc[-1]:,.2f}"
                elif len(market_data.columns) > 0:
                    current_price = f"${market_data.iloc[-1, -1]:,.2f}"
            except Exception:
                pass
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ 30 –¥–Ω–µ–π
        change_30d = 'N/A'
        if market_data is not None and not market_data.empty:
            try:
                if 'close' in market_data.columns and len(market_data) >= 30:
                    price_now = market_data['close'].iloc[-1]
                    price_30d = market_data['close'].iloc[-30]
                    change_30d = f"{(price_now - price_30d) / price_30d * 100:+.2f}"
            except Exception:
                pass
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ/–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
        articles = sentiment.get('articles', [])
        positive_count = sum(1 for a in articles if (a.get('sentiment_score', 0) or 0) > 0.1)
        negative_count = sum(1 for a in articles if (a.get('sentiment_score', 0) or 0) < -0.1)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –Ω–∞ —Ä—É—Å—Å–∫–æ–º
        recommendation = analysis.get('recommendation', 'hold').upper()
        rec_map = {'BUY': '–ü–æ–∫—É–ø–∫–∞', 'SELL': '–ü—Ä–æ–¥–∞–∂–∞', 'HOLD': '–£–¥–µ—Ä–∂–∞–Ω–∏–µ'}
        invest_decision = rec_map.get(recommendation, '–£–¥–µ—Ä–∂–∞–Ω–∏–µ')
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º overall_score –≤ —à–∫–∞–ª—É 0-10
        overall_score_raw = analysis.get('overall_score', 0.0)
        total_score = max(0, min(10, (overall_score_raw + 1) * 5))  # -1..1 -> 0..10
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å –∑–∞–º–µ–Ω
        replacements = {
            # –î–∞—Ç–∞ –∏ –∞–≤—Ç–æ—Ä
            '{{date}}': datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC'),
            '{{author}}': 'AI-Platform',
            
            # –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            '{{ASSET_NAME}}': symbol,
            '{{TICKER}}': symbol,
            '{{ASSET}}': symbol,  # –î–ª—è —Ç–∞–±–ª–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            '{{PRICE}}': current_price.replace('$', '') if current_price != 'N/A' else 'N/A',
            '{{MARKET_CAP}}': str(analysis.get('market_cap', 'N/A')),
            '{{TVL}}': str(analysis.get('tvl', 'N/A')),
            '{{CHANGE_30D}}': change_30d.replace('%', '') if change_30d != 'N/A' else 'N/A',
            '{{RISK_LEVEL}}': analysis.get('risk_level', 'N/A').upper(),
            '{{FUNDAMENTAL_SCORE}}': f"{analysis.get('fundamental_score', total_score):.1f}",
            '{{TOTAL_SCORE}}': f"{total_score:.1f}",
            
            # –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã
            '{{POTENTIAL}}': '–°—Ä–µ–¥–Ω–∏–π' if total_score > 5 else '–ù–∏–∑–∫–∏–π',
            '{{DRIVERS}}': ', '.join(sentiment.get('key_themes', [])[:3]) or '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö',
            '{{RISKS}}': f"–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: {analysis.get('risk_level', 'N/A')}",
            '{{INVEST_DECISION}}': invest_decision,
            '{{SUMMARY_FORECAST}}': f"–û—Ü–µ–Ω–∫–∞ {total_score:.1f}/10. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {invest_decision}",
            
            # Santiment –¥–∞–Ω–Ω—ã–µ
            '{{SENTIMENT_SCORE}}': f"{overall_sentiment.get('score', 0):.2f}",
            '{{NEWS_POSITIVE_CHANGE}}': 'N/A',  # –¢—Ä–µ–±—É—é—Ç—Å—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
            '{{DEV_ACTIVITY_TREND}}': 'N/A',
            '{{WHALE_ACTIVITY}}': 'N/A',
            
            # –¶–µ–Ω–∞ –∏ –æ–±—ä–µ–º—ã
            '{{PRICE_TRENDS}}': f"–¢—Ä–µ–Ω–¥: {technical.get('trend', 'N/A')}. MA7: {ma.get('MA7', 0):.2f}, MA30: {ma.get('MA30', 0):.2f}",
            '{{VOLUME_INSIGHT}}': '–ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–º–æ–≤ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö',
            
            # Sentiment –º–µ—Ç—Ä–∏–∫–∏
            '{{POSITIVE_NEWS_COUNT}}': str(positive_count),
            '{{NEGATIVE_NEWS_COUNT}}': str(negative_count),
            '{{SOCIAL_ACTIVITY_CHANGE}}': 'N/A',
            '{{DIVERGENCE_STATUS}}': '–¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞',
            '{{SENTIMENT_COMMENT}}': f"–û–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {overall_sentiment.get('label', 'N/A')} ({overall_sentiment.get('score', 0):.2f})",
            
            # On-chain –¥–∞–Ω–Ω—ã–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é N/A, —Ç–∞–∫ –∫–∞–∫ –Ω–µ—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
            '{{ACTIVE_ADDRESSES}}': str(analysis.get('onchain', {}).get('active_addresses', 'N/A')),
            '{{CHANGE_ADDRESSES}}': str(analysis.get('onchain', {}).get('change_addresses', 'N/A')),
            '{{TX_PER_DAY}}': str(analysis.get('onchain', {}).get('tx_per_day', 'N/A')),
            '{{CHANGE_TX}}': str(analysis.get('onchain', {}).get('change_tx', 'N/A')),
            '{{WHALE_TX}}': str(analysis.get('onchain', {}).get('whale_tx', 'N/A')),
            '{{CHANGE_WHALE_TX}}': str(analysis.get('onchain', {}).get('change_whale_tx', 'N/A')),
            '{{EX_OUTFLOW}}': str(analysis.get('onchain', {}).get('exchange_outflow', 'N/A')),
            '{{CHANGE_EX_OUTFLOW}}': str(analysis.get('onchain', {}).get('change_exchange_outflow', 'N/A')),
            
            # Network Health
            '{{CHANGE_TVL}}': str(analysis.get('change_tvl', 'N/A')),
            '{{DEV_ACTIVITY}}': str(analysis.get('network_health', {}).get('dev_activity', 'N/A')),
            '{{DEV_ACTIVITY_CHANGE}}': str(analysis.get('network_health', {}).get('dev_activity_change', 'N/A')),
            '{{DAU}}': str(analysis.get('network_health', {}).get('dau', 'N/A')),
            '{{CHANGE_DAU}}': str(analysis.get('network_health', {}).get('change_dau', 'N/A')),
            
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
            '{{ROI}}': str(analysis.get('roi_ytd', 'N/A')),
            
            # –§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            '{{PROJECT_DESCRIPTION}}': analysis.get('project_description', '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è'),
            '{{CONSENSUS}}': analysis.get('consensus', 'N/A'),
            '{{SCALABILITY}}': analysis.get('scalability', 'N/A'),
            '{{SECURITY_FEATURES}}': analysis.get('security_features', 'N/A'),
            '{{INNOVATIONS}}': analysis.get('innovations', 'N/A'),
            '{{FOUNDERS}}': analysis.get('team_investors', 'N/A'),
            '{{FUNDS}}': 'N/A',
            '{{ADVISORS}}': 'N/A',
            
            # Roadmap
            '{{ROADMAP_ITEM_1}}': 'N/A',
            '{{DATE_1}}': 'N/A',
            '{{ROADMAP_ITEM_2}}': 'N/A',
            '{{DATE_2}}': 'N/A',
            '{{ROADMAP_ITEM_3}}': 'N/A',
            '{{DATE_3}}': 'N/A',
            
            # –¢–æ–∫–µ–Ω–æ–º–∏–∫–∞
            '{{MAX_SUPPLY}}': str(analysis.get('max_supply', 'N/A')),
            '{{CIRC_SUPPLY}}': str(analysis.get('circulating_supply', 'N/A')),
            '{{INFLATION}}': str(analysis.get('inflation', 'N/A')),
            '{{TOKEN_MECHANISM}}': analysis.get('token_mechanism', 'N/A'),
            '{{STAKING_YIELD}}': str(analysis.get('staking_yield', 'N/A')),
            '{{TOKENOMICS_COMMENT}}': '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–∫–µ–Ω–æ–º–∏–∫–µ',
            
            # –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
            '{{NVT}}': str(analysis.get('nvt', 'N/A')),
            '{{NVT_COMMENT}}': '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑',
            '{{PS_RATIO}}': str(analysis.get('ps_ratio', 'N/A')),
            '{{PS_COMMENT}}': '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑',
            '{{SHARPE_RATIO}}': str(analysis.get('sharpe_ratio', 'N/A')),
            '{{SHARPE_COMMENT}}': '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑',
            '{{ROI_COMMENT}}': '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑',
            '{{VOLATILITY}}': str(analysis.get('volatility', 'N/A')),
            '{{VOL_COMMENT}}': '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑',
            
            # –ö–æ–º—å—é–Ω–∏—Ç–∏
            '{{TWITTER_FOLLOWERS}}': str(analysis.get('social', {}).get('twitter_followers', 'N/A')),
            '{{TWITTER_CHANGE}}': str(analysis.get('social', {}).get('twitter_change', 'N/A')),
            '{{TELEGRAM_MEMBERS}}': str(analysis.get('social', {}).get('telegram_members', 'N/A')),
            '{{TELEGRAM_CHANGE}}': str(analysis.get('social', {}).get('telegram_change', 'N/A')),
            '{{COMMITS}}': str(analysis.get('network_health', {}).get('commits', 'N/A')),
            '{{COMMITS_CHANGE}}': str(analysis.get('network_health', {}).get('commits_change', 'N/A')),
            '{{ECOSYSTEM_SIZE}}': str(analysis.get('ecosystem_size', 'N/A')),
            '{{CHANGE_ECOSYSTEM}}': str(analysis.get('change_ecosystem', 'N/A')),
            '{{COMMUNITY_COMMENT}}': '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–º—å—é–Ω–∏—Ç–∏',
            
            # –ù–æ–≤–æ—Å—Ç–∏
            '{{NEWS_COUNT}}': str(len(articles)),
            '{{TOP_SOURCES}}': '–†–∞–∑–ª–∏—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏',
            '{{TOP_TOPICS}}': ', '.join(sentiment.get('key_themes', [])[:5]) or 'N/A',
            '{{NEWS_SUMMARY}}': f"–ù–∞–π–¥–µ–Ω–æ {len(articles)} –Ω–æ–≤–æ—Å—Ç–µ–π. –û–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {overall_sentiment.get('label', 'N/A')}",
            
            # –°–æ—Ü–∏–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            '{{TWITTER_MENTIONS}}': str(analysis.get('social', {}).get('twitter_mentions', 'N/A')),
            '{{TWITTER_CHANGE}}': str(analysis.get('social', {}).get('twitter_change', 'N/A')),
            '{{TWITTER_SENTIMENT}}': str(analysis.get('social', {}).get('twitter_sentiment', 'N/A')),
            '{{REDDIT_POSTS}}': str(analysis.get('social', {}).get('reddit_posts', 'N/A')),
            '{{REDDIT_CHANGE}}': str(analysis.get('social', {}).get('reddit_change', 'N/A')),
            '{{REDDIT_SENTIMENT}}': str(analysis.get('social', {}).get('reddit_sentiment', 'N/A')),
            '{{TELEGRAM_ACTIVITY}}': str(analysis.get('social', {}).get('telegram_activity', 'N/A')),
            '{{TELEGRAM_CHANGE}}': str(analysis.get('social', {}).get('telegram_change', 'N/A')),
            '{{TELEGRAM_SENTIMENT}}': str(analysis.get('social', {}).get('telegram_sentiment', 'N/A')),
            '{{SANTIMENT_SUMMARY}}': analysis.get('santiment_summary', overall_sentiment.get('label', 'N/A')),
            
            # –†–∏—Å–∫–∏
            '{{TECH_RISK}}': 'N/A',
            '{{PROB1}}': 'N/A',
            '{{IMPACT1}}': 'N/A',
            '{{COMMENT1}}': '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑',
            '{{REG_RISK}}': 'N/A',
            '{{PROB2}}': 'N/A',
            '{{IMPACT2}}': 'N/A',
            '{{COMMENT2}}': '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑',
            '{{MARKET_RISK}}': analysis.get('risk_level', 'N/A'),
            '{{PROB3}}': '–°—Ä–µ–¥–Ω—è—è',
            '{{IMPACT3}}': '–í—ã—Å–æ–∫–æ–µ',
            '{{COMMENT3}}': f"–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: {analysis.get('risk_level', 'N/A')}",
            
            # –ü—Ä–æ–≥–Ω–æ–∑
            '{{BULLISH_PROB}}': '30',
            '{{BULLISH_TARGET}}': 'N/A',
            '{{BULLISH_COMMENT}}': '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑',
            '{{NEUTRAL_PROB}}': '40',
            '{{NEUTRAL_TARGET}}': current_price.replace('$', '') if current_price != 'N/A' else 'N/A',
            '{{NEUTRAL_COMMENT}}': '–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö —É—Ä–æ–≤–Ω–µ–π',
            '{{BEARISH_PROB}}': '30',
            '{{BEARISH_TARGET}}': 'N/A',
            '{{BEARISH_COMMENT}}': '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑',
            '{{FORECAST_SUMMARY}}': f"–û—Ü–µ–Ω–∫–∞: {total_score:.1f}/10. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {invest_decision}",
            
            # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
            '{{SOCIAL_SCORE}}': f"{analysis.get('social_score', total_score * 0.8):.1f}",
            '{{ONCHAIN_SCORE}}': f"{analysis.get('onchain_score', total_score * 0.7):.1f}",
            '{{TOKEN_SCORE}}': f"{analysis.get('token_score', total_score * 0.6):.1f}",
            '{{GROWTH_SCORE}}': f"{analysis.get('growth_score', total_score * 0.9):.1f}",
            '{{FINAL_RECOMMENDATION}}': invest_decision,
            '{{BUY_ZONE_LOW}}': str(analysis.get('buy_zone_low', 'N/A')),
            '{{BUY_ZONE_HIGH}}': str(analysis.get('buy_zone_high', 'N/A')),
            
            # –ò—Å—Ç–æ—á–Ω–∏–∫–∏
            '{{CMC_LINK}}': f"https://coinmarketcap.com/currencies/{symbol.lower()}/",
            '{{SANTIMENT_LINK}}': f"https://santiment.net/{symbol.lower()}",
            '{{DEFI_LLAMA_LINK}}': 'https://defillama.com/',
            '{{GLASSNODE_LINK}}': 'https://glassnode.com/',
            '{{GITHUB_LINK}}': 'N/A',
            '{{WHITEPAPER_LINK}}': 'N/A',
        }
        
        # –ó–∞–º–µ–Ω—è–µ–º –≤—Å–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
        report = template
        for placeholder, value in replacements.items():
            report = report.replace(placeholder, str(value))
        
        return report

    def create_charts(self, market_data, news_articles: Optional[List[Dict[str, Any]]] = None) -> List[Chart]:
        charts: List[Chart] = []
        try:
            fig, ax = plt.subplots(figsize=(6, 3))
            market_data['close'].tail(60).plot(ax=ax, title='Close Price (60d)')
            ax.set_xlabel('Date')
            ax.set_ylabel('Price')
            buf = io.BytesIO()
            plt.tight_layout()
            fig.savefig(buf, format='png')
            plt.close(fig)
            charts.append(Chart(title='–¶–µ–Ω–∞ (60 –¥–Ω–µ–π)', image_bytes=buf.getvalue()))
        except Exception:
            pass

        # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (STD 14 –Ω–∞ 90 –¥–Ω–µ–π)
        try:
            if 'close' in market_data.columns:
                rolling_std = market_data['close'].tail(90).rolling(window=14).std()
                fig, ax = plt.subplots(figsize=(6, 3))
                rolling_std.plot(ax=ax, title='Volatility (STD 14, 90d)')
                ax.set_xlabel('Date')
                ax.set_ylabel('STD')
                buf = io.BytesIO()
                plt.tight_layout()
                fig.savefig(buf, format='png')
                plt.close(fig)
                charts.append(Chart(title='–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (90 –¥–Ω–µ–π)', image_bytes=buf.getvalue()))
        except Exception:
            pass

        # –û–±—ä–µ–º
        try:
            if 'volume' in market_data.columns:
                fig, ax = plt.subplots(figsize=(6, 3))
                market_data['volume'].tail(60).plot(ax=ax, title='Volume (60d)')
                ax.set_xlabel('Date')
                ax.set_ylabel('Volume')
                buf = io.BytesIO()
                plt.tight_layout()
                fig.savefig(buf, format='png')
                plt.close(fig)
                charts.append(Chart(title='–û–±—ä–µ–º (60 –¥–Ω–µ–π)', image_bytes=buf.getvalue()))
        except Exception:
            pass

        # –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–µ–π (7-–¥–Ω–µ–≤–Ω–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –¥–Ω—è–º)
        try:
            if news_articles:
                import pandas as pd
                rows = []
                for a in news_articles:
                    ts = a.get('published_at') or a.get('publishedAt')
                    score = a.get('sentiment_score')
                    if isinstance(ts, str):
                        try:
                            ts = pd.to_datetime(ts)
                        except Exception:
                            ts = None
                    if ts is not None and score is not None:
                        rows.append({"ts": ts, "score": float(score)})
                if rows:
                    df = pd.DataFrame(rows)
                    df['date'] = df['ts'].dt.date
                    grouped = df.groupby('date')['score'].mean().rolling(7).mean()
                    fig, ax = plt.subplots(figsize=(6, 3))
                    grouped.plot(ax=ax, title='Sentiment (7d MA)')
                    ax.set_xlabel('Date')
                    ax.set_ylabel('Score')
                    buf = io.BytesIO()
                    plt.tight_layout()
                    fig.savefig(buf, format='png')
                    plt.close(fig)
                    charts.append(Chart(title='–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–µ–π (7d MA)', image_bytes=buf.getvalue()))
        except Exception:
            pass
        return charts

    def add_timeframe_disclaimer(self, text: str) -> str:
        disclaimer = "–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –¥–Ω–µ–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (1d). –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å—é –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏."
        return f"{text}\n\n{disclaimer}"

    def generate_pdf_report(self, analysis: Dict[str, Any], charts: List[Chart] = None) -> bytes:
        charts = charts or []
        buffer = io.BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4)
        
        # –°–æ–∑–¥–∞–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å—Ç–∏–ª–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —à—Ä–∏—Ñ—Ç–∞–º–∏
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        from reportlab.lib.fonts import addMapping
        from reportlab.lib.colors import HexColor
        
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —à—Ä–∏—Ñ—Ç—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∏—Ä–∏–ª–ª–∏—Ü—ã (Noto Sans ‚Üí DejaVu Sans ‚Üí Liberation Sans)
        try:
            noto_candidates = [
                ('/usr/share/fonts/noto/NotoSans-Regular.ttf', '/usr/share/fonts/noto/NotoSans-Bold.ttf'),
                ('/usr/share/fonts/TTF/NotoSans-Regular.ttf', '/usr/share/fonts/TTF/NotoSans-Bold.ttf'),
            ]
            dejavu_candidates = [
                ('/usr/share/fonts/TTF/DejaVuSans.ttf', '/usr/share/fonts/TTF/DejaVuSans-Bold.ttf'),
                ('/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', '/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf'),
            ]
            liberation_candidates = [
                ('/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', '/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf')
            ]

            font_name = None
            for regular, bold in noto_candidates + dejavu_candidates + liberation_candidates:
                try:
                    pdfmetrics.registerFont(TTFont('CustomFont', regular))
                    pdfmetrics.registerFont(TTFont('CustomFont-Bold', bold))
                    font_name = 'CustomFont'
                    break
                except Exception:
                    continue

            if not font_name:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —à—Ä–∏—Ñ—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Unicode –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–∏–π fallback
                from reportlab.pdfbase.cidfonts import UnicodeCIDFont
                pdfmetrics.registerFont(UnicodeCIDFont('HeiseiKakuGo-W5'))
                font_name = 'HeiseiKakuGo-W5'

        except Exception:
            # Fallback –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —à—Ä–∏—Ñ—Ç—ã
            font_name = 'Helvetica'
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç–∏–ª–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —à—Ä–∏—Ñ—Ç–∞–º–∏
        styles = getSampleStyleSheet()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∏–ª–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞—à–µ–≥–æ —à—Ä–∏—Ñ—Ç–∞
        styles['Normal'].fontName = font_name
        styles['Heading1'].fontName = 'CustomFont-Bold' if font_name == 'CustomFont' else font_name
        styles['Heading2'].fontName = 'CustomFont-Bold' if font_name == 'CustomFont' else font_name
        styles['Title'].fontName = 'CustomFont-Bold' if font_name == 'CustomFont' else font_name
        
        # –°–æ–∑–¥–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–∏–ª–∏
        custom_styles = {
            'Title': ParagraphStyle(
                'CustomTitle',
                parent=styles['Title'],
                fontName=font_name,
                fontSize=18,
                spaceAfter=20,
                alignment=1  # Center
            ),
            'Heading1': ParagraphStyle(
                'CustomHeading1',
                parent=styles['Heading1'],
                fontName=('CustomFont-Bold' if font_name == 'CustomFont' else font_name),
                fontSize=14,
                spaceAfter=12,
                textColor=HexColor('#2E86AB')
            ),
            'Heading2': ParagraphStyle(
                'CustomHeading2',
                parent=styles['Heading2'],
                fontName=('CustomFont-Bold' if font_name == 'CustomFont' else font_name),
                fontSize=12,
                spaceAfter=8,
                textColor=HexColor('#A23B72')
            ),
            'BodyText': ParagraphStyle(
                'CustomBodyText',
                parent=styles['BodyText'],
                fontName=font_name,
                fontSize=10,
                spaceAfter=6
            )
        }

        elements: List[Any] = []

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –¥–∞—Ç–∞
        elements.append(Paragraph(f"üí† –§–∏–Ω–∞–Ω—Å–æ–≤–æ-–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –û—Ç—á—ë—Ç –ø–æ –ö—Ä–∏–ø—Ç–æ-–ê–∫—Ç–∏–≤—É", custom_styles['Title']))
        elements.append(Paragraph(f"–î–∞—Ç–∞ –æ—Ç—á—ë—Ç–∞: {analysis.get('timestamp', 'N/A')}", custom_styles['BodyText']))
        elements.append(Spacer(1, 16))

        # 0. Executive Summary
        elements.append(Paragraph("üìë 0. –ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ (Executive Summary)", custom_styles['Heading1']))
        summary_data = [["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ó–Ω–∞—á–µ–Ω–∏–µ"]]
        summary_data += [
            ["–ê–∫—Ç–∏–≤ / –¢–∏–∫–µ—Ä", f"{analysis.get('symbol', 'N/A')}"],
            ["–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞", f"{analysis.get('current_price', 'N/A')}",],
            ["–†—ã–Ω–æ—á–Ω–∞—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è", f"{analysis.get('market_cap', 'N/A')}",],
            ["TVL", f"{analysis.get('tvl', 'N/A')}",],
            ["–ò–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ 30–¥", f"{analysis.get('change_30d', 'N/A')}",],
            ["–û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞", f"{analysis.get('risk_level', 'N/A')}",],
            ["–§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è —Å–∏–ª–∞", f"{analysis.get('fundamental_score', 'N/A')}",],
            ["–û–±—â–∏–π —Ä–µ–π—Ç–∏–Ω–≥", f"{analysis.get('total_score', analysis.get('overall_score', 0))}",],
        ]
        summary_table = Table(summary_data)
        summary_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2E86AB')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.lightgrey),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.black),
        ]))
        elements.append(summary_table)
        elements.append(Spacer(1, 16))

        # 1. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        elements.append(Paragraph("üìä 1. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è", custom_styles['Heading1']))
        elements.append(Paragraph("1.1 üìà –¶–µ–Ω–∞ –∏ –æ–±—ä—ë–º—ã —Ç–æ—Ä–≥–æ–≤", custom_styles['Heading2']))
        if charts:
            from reportlab.platypus import Image
            for ch in charts:
                try:
                    if any(k in ch.title for k in ["–¶–µ–Ω–∞", "Volume", "–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å"]):
                        img_buf = io.BytesIO(ch.image_bytes)
                        elements.append(Paragraph(ch.title, custom_styles['BodyText']))
                        elements.append(Image(img_buf, width=500, height=250))
                        elements.append(Spacer(1, 10))
                except Exception:
                    continue

        elements.append(Paragraph("1.2 üß† Sentiment –∏ –Ω–æ–≤–æ—Å—Ç–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞", custom_styles['Heading2']))
        sent_block = analysis.get('sentiment', {})
        if sent_block:
            elements.append(Paragraph(
                f"–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {sent_block.get('overall', {}).get('label', 'N/A')} ({sent_block.get('overall', {}).get('score', 0):.2f})",
                custom_styles['BodyText']
            ))
        elements.append(Spacer(1, 12))

        # 1.3 üì° On-chain –¥–∞–Ω–Ω—ã–µ
        elements.append(Paragraph("1.3 üì° On-chain –¥–∞–Ω–Ω—ã–µ", custom_styles['Heading2']))
        onchain = analysis.get('onchain', {})
        onchain_rows = [["–ú–µ—Ç—Ä–∏–∫–∞", "–¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ", "–ò–∑–º–µ–Ω–µ–Ω–∏–µ (30–¥)"]]
        onchain_rows += [
            ["–ê–∫—Ç–∏–≤–Ω—ã–µ –∞–¥—Ä–µ—Å–∞", f"{onchain.get('active_addresses','N/A')}", f"{onchain.get('change_addresses','N/A')}"] ,
            ["–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ / –¥–µ–Ω—å", f"{onchain.get('tx_per_day','N/A')}", f"{onchain.get('change_tx','N/A')}"] ,
            ["Whale-—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏", f"{onchain.get('whale_tx','N/A')}", f"{onchain.get('change_whale_tx','N/A')}"] ,
            ["Exchange Outflow", f"{onchain.get('exchange_outflow','N/A')}", f"{onchain.get('change_exchange_outflow','N/A')}"] ,
        ]
        elements.append(Table(onchain_rows))
        elements.append(Spacer(1, 8))

        # 1.4 ‚öôÔ∏è Network Health
        elements.append(Paragraph("1.4 ‚öôÔ∏è Network Health", custom_styles['Heading2']))
        nh = analysis.get('network_health', {})
        nh_rows = [["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ó–Ω–∞—á–µ–Ω–∏–µ", "–ò–∑–º–µ–Ω–µ–Ω–∏–µ"],
                   ["TVL", f"{analysis.get('tvl','N/A')}", f"{analysis.get('change_tvl','N/A')}"] ,
                   ["–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å Dev", f"{nh.get('dev_activity','N/A')}", f"{nh.get('dev_activity_change','N/A')}"] ,
                   ["DAU", f"{nh.get('dau','N/A')}", f"{nh.get('change_dau','N/A')}"] ]
        elements.append(Table(nh_rows))
        elements.append(Spacer(1, 8))

        # 1.5 üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–Ω–∞–ª–æ–≥–∞–º–∏
        elements.append(Paragraph("1.5 üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–Ω–∞–ª–æ–≥–∞–º–∏", custom_styles['Heading2']))
        comp_rows = [["–ê–∫—Ç–∏–≤", "–ö–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è", "TVL", "ROI (YTD)", "Dev Activity", "Sentiment"],
                     ["ETH", "$360B", "$95B", "+48%", "9.1", "0.73"],
                     ["SOL", "$75B", "$12B", "+210%", "8.7", "0.68"],
                     [analysis.get('symbol','N/A'), f"{analysis.get('market_cap','N/A')}", f"{analysis.get('tvl','N/A')}", f"{analysis.get('roi_ytd','N/A')}", f"{nh.get('dev_activity','N/A')}", f"{(analysis.get('sentiment',{}).get('overall',{}) or {}).get('score','N/A')}"]]
        elements.append(Table(comp_rows))
        elements.append(Spacer(1, 12))

        # 2. –§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        elements.append(Paragraph("üß† 2. –§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", custom_styles['Heading1']))
        elements.append(Paragraph("2.1 –ú–∏—Å—Å–∏—è –∏ –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ", custom_styles['Heading2']))
        elements.append(Paragraph(f"{analysis.get('project_description', 'N/A')}", custom_styles['BodyText']))
        elements.append(Paragraph("2.2 –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", custom_styles['Heading2']))
        elements.append(Paragraph(f"–ö–æ–Ω—Å–µ–Ω—Å—É—Å: {analysis.get('consensus','N/A')} | –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å: {analysis.get('scalability','N/A')} | –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: {analysis.get('security_features','N/A')} | –ò–Ω–Ω–æ–≤–∞—Ü–∏–∏: {analysis.get('innovations','N/A')}", custom_styles['BodyText']))
        elements.append(Paragraph("2.3 –ö–æ–º–∞–Ω–¥–∞ –∏ –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã", custom_styles['Heading2']))
        elements.append(Paragraph(f"{analysis.get('team_investors', 'N/A')}", custom_styles['BodyText']))
        elements.append(Paragraph("2.4 Roadmap", custom_styles['Heading2']))
        rm = analysis.get('roadmap', [])
        rm_rows = [["–≠—Ç–∞–ø", "–°–æ—Å—Ç–æ—è–Ω–∏–µ", "–î–∞—Ç–∞"]]
        for item in rm[:3]:
            rm_rows.append([item.get('title','N/A'), item.get('status','N/A'), item.get('date','N/A')])
        if len(rm_rows) == 1:
            rm_rows.append(["N/A","N/A","N/A"])
        elements.append(Table(rm_rows))
        elements.append(Spacer(1, 12))

        # 3. –¢–æ–∫–µ–Ω–æ–º–∏–∫–∞
        elements.append(Paragraph("üí∞ 3. –¢–æ–∫–µ–Ω–æ–º–∏–∫–∞", custom_styles['Heading1']))
        tokenomics_rows = [["–ú–µ—Ç—Ä–∏–∫–∞", "–ó–Ω–∞—á–µ–Ω–∏–µ"]]
        tokenomics_rows += [
            ["–û–±—â–∏–π –æ–±—ä—ë–º —ç–º–∏—Å—Å–∏–∏", f"{analysis.get('max_supply', 'N/A')}"] ,
            ["–¶–∏—Ä–∫—É–ª–∏—Ä—É—é—â–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ", f"{analysis.get('circulating_supply', 'N/A')}"] ,
            ["–ò–Ω—Ñ–ª—è—Ü–∏—è", f"{analysis.get('inflation', 'N/A')}"] ,
            ["–ú–µ—Ö–∞–Ω–∏–∑–º", f"{analysis.get('token_mechanism', 'N/A')}"] ,
            ["Staking Yield", f"{analysis.get('staking_yield', 'N/A')}"] ,
        ]
        tokenomics_table = Table(tokenomics_rows)
        tokenomics_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2E86AB')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.black),
        ]))
        elements.append(tokenomics_table)
        elements.append(Spacer(1, 12))

        # 4. –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        elements.append(Paragraph("üìà 4. –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏", custom_styles['Heading1']))
        fin_rows = [["–ú–µ—Ç—Ä–∏–∫–∞", "–ó–Ω–∞—á–µ–Ω–∏–µ"]]
        fin_rows += [
            ["NVT", f"{analysis.get('nvt', 'N/A')}"] ,
            ["P/S", f"{analysis.get('ps_ratio', 'N/A')}"] ,
            ["Sharpe Ratio", f"{analysis.get('sharpe_ratio', 'N/A')}"] ,
            ["ROI (YTD)", f"{analysis.get('roi_ytd', 'N/A')}"] ,
            ["–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å", f"{analysis.get('volatility', 'N/A')}"] ,
        ]
        fin_table = Table(fin_rows)
        fin_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2E86AB')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.black),
        ]))
        elements.append(fin_table)
        elements.append(Spacer(1, 12))

        # 5. –ö–æ–º—å—é–Ω–∏—Ç–∏ –∏ —ç–∫–æ—Å–∏—Å—Ç–µ–º–∞
        elements.append(Paragraph("üåê 5. –ö–æ–º—å—é–Ω–∏—Ç–∏ –∏ —ç–∫–æ—Å–∏—Å—Ç–µ–º–∞", custom_styles['Heading1']))
        elements.append(Paragraph(f"–ú–µ—Ç—Ä–∏–∫–∏ –∫–æ–º—å—é–Ω–∏—Ç–∏: {analysis.get('community_metrics', 'N/A')}", custom_styles['BodyText']))
        elements.append(Spacer(1, 12))

        # 6. –ê–Ω–∞–ª–∏–∑ Santiment / –ù–æ–≤–æ—Å—Ç–µ–π
        elements.append(Paragraph("üßæ 6. –ê–Ω–∞–ª–∏–∑ Santiment / –ù–æ–≤–æ—Å—Ç–µ–π", custom_styles['Heading1']))
        sentiment = analysis.get('sentiment', {})
        overall = sentiment.get('overall', {})
        # 6.1 –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –ø–æ–ª—è
        elements.append(Paragraph("6.1 –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –ø–æ–ª—è", custom_styles['Heading2']))
        articles = sentiment.get('articles', [])
        elements.append(Paragraph(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π: {len(articles)}", custom_styles['BodyText']))
        if articles:
            news_data = [["–ó–∞–≥–æ–ª–æ–≤–æ–∫", "–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å", "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"]]
            for article in articles[:5]:
                title = article.get('title', 'N/A')
                news_data.append([title[:60] + ("..." if len(title) > 60 else ""), f"{article.get('sentiment_score', 0):.2f}", f"{article.get('relevance_score', 0):.2f}"])
            news_table = Table(news_data)
            news_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#A23B72')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 10),
                ('BACKGROUND', (0, 1), (-1, -1), colors.lightgrey),
                ('GRID', (0, 0), (-1, -1), 0.5, colors.black),
                ('FONTSIZE', (0, 1), (-1, -1), 8),
            ]))
            elements.append(news_table)
        # 6.2 –°–æ—Ü–∏–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        elements.append(Paragraph("6.2 –°–æ—Ü–∏–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å", custom_styles['Heading2']))
        social = analysis.get('social', {})
        social_rows = [["–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞", "–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å", "–ò–∑–º–µ–Ω–µ–Ω–∏–µ", "–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å"],
                       ["Twitter", f"{social.get('twitter_mentions','N/A')}", f"{social.get('twitter_change','N/A')}", f"{social.get('twitter_sentiment','N/A')}"] ,
                       ["Reddit", f"{social.get('reddit_posts','N/A')}", f"{social.get('reddit_change','N/A')}", f"{social.get('reddit_sentiment','N/A')}"] ,
                       ["Telegram", f"{social.get('telegram_activity','N/A')}", f"{social.get('telegram_change','N/A')}", f"{social.get('telegram_sentiment','N/A')}"] ]
        elements.append(Table(social_rows))
        # 6.3 –ò—Ç–æ–≥ Santiment –∞–Ω–∞–ª–∏–∑–∞
        elements.append(Paragraph("6.3 –ò—Ç–æ–≥ Santiment –∞–Ω–∞–ª–∏–∑–∞", custom_styles['Heading2']))
        elements.append(Paragraph(f"{analysis.get('santiment_summary', overall.get('label',''))}", custom_styles['BodyText']))
        elements.append(Spacer(1, 12))

        # 7. –†–∏—Å–∫–∏ –∏ —É—è–∑–≤–∏–º–æ—Å—Ç–∏
        elements.append(Paragraph("‚ö†Ô∏è 7. –†–∏—Å–∫–∏ –∏ —É—è–∑–≤–∏–º–æ—Å—Ç–∏", custom_styles['Heading1']))
        risks = analysis.get('risks', [])
        if risks:
            risk_rows = [["–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–†–∏—Å–∫", "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å", "–í–ª–∏—è–Ω–∏–µ"]]
            for r in risks[:5]:
                risk_rows.append([
                    r.get('category', 'N/A'), r.get('title', 'N/A'), r.get('probability', 'N/A'), r.get('impact', 'N/A')
                ])
            risk_table = Table(risk_rows)
            risk_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2E86AB')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('GRID', (0, 0), (-1, -1), 0.5, colors.black),
            ]))
            elements.append(risk_table)
        elements.append(Spacer(1, 12))

        # 8. –ü—Ä–æ–≥–Ω–æ–∑ –∏ —Å—Ü–µ–Ω–∞—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        elements.append(Paragraph("üîÆ 8. –ü—Ä–æ–≥–Ω–æ–∑ –∏ —Å—Ü–µ–Ω–∞—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑", custom_styles['Heading1']))
        scenarios = analysis.get('scenarios', {})
        if scenarios:
            scen_rows = [["–°—Ü–µ–Ω–∞—Ä–∏–π", "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å", "–¶–µ–ª—å —Ü–µ–Ω—ã"]]
            for name in ("Bullish", "Neutral", "Bearish"):
                s = scenarios.get(name.lower(), {})
                scen_rows.append([name, s.get('prob', 'N/A'), s.get('target', 'N/A')])
            scen_table = Table(scen_rows)
            scen_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2E86AB')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('GRID', (0, 0), (-1, -1), 0.5, colors.black),
            ]))
            elements.append(scen_table)
        elements.append(Spacer(1, 12))

        # 9. –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        elements.append(Paragraph("üßæ 9. –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞", custom_styles['Heading1']))
        eval_rows = [["–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–ë–∞–ª–ª (0‚Äì10)"],
                     ["–§—É–Ω–¥–∞–º–µ–Ω—Ç", f"{analysis.get('fundamental_score','N/A')}"] ,
                     ["–°–æ—Ü. –º–µ—Ç—Ä–∏–∫–∏ (Santiment)", f"{analysis.get('social_score','N/A')}"] ,
                     ["–û–Ω—á–µ–π–Ω –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å", f"{analysis.get('onchain_score','N/A')}"] ,
                     ["–¢–æ–∫–µ–Ω–æ–º–∏–∫–∞", f"{analysis.get('token_score','N/A')}"] ,
                     ["–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞", f"{analysis.get('growth_score','N/A')}"] ]
        elements.append(Table(eval_rows))
        elements.append(Paragraph(f"–ò—Ç–æ–≥: {analysis.get('total_score', analysis.get('overall_score', 'N/A'))} / 10", custom_styles['BodyText']))
        elements.append(Paragraph(f"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {analysis.get('final_recommendation', analysis.get('recommendation', 'N/A'))}", custom_styles['BodyText']))
        if analysis.get('buy_zone_low') or analysis.get('buy_zone_high'):
            elements.append(Paragraph(f"–ò–Ω–≤–µ—Å—Ç-–∑–æ–Ω–∞: ${analysis.get('buy_zone_low','N/A')} ‚Äì ${analysis.get('buy_zone_high','N/A')}", custom_styles['BodyText']))
        elements.append(Spacer(1, 12))

        # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        data_sources = analysis.get('data_sources', [])
        if data_sources:
            elements.append(Paragraph("üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã", custom_styles['Heading1']))
            elements.append(Paragraph(f"{', '.join(data_sources)}", custom_styles['BodyText']))
            elements.append(Spacer(1, 12))

        # Disclaimer
        elements.append(Paragraph("‚ö†Ô∏è –í–ê–ñ–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø", custom_styles['Heading1']))
        disclaimer_text = """
        ‚Ä¢ –ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –¥–Ω–µ–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (1d) –∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç—è—Ö
        ‚Ä¢ –ù–µ —è–≤–ª—è–µ—Ç—Å—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π
        ‚Ä¢ –ü—Ä–æ–≤–æ–¥–∏—Ç–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        ‚Ä¢ –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã - –≤—ã—Å–æ–∫–æ—Ä–∏—Å–∫–æ–≤–∞–Ω–Ω—ã–µ –∞–∫—Ç–∏–≤—ã
        ‚Ä¢ –í–æ–∑–º–æ–∂–Ω—ã –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏ –∫–∞–ø–∏—Ç–∞–ª–∞
        """
        elements.append(Paragraph(disclaimer_text, custom_styles['BodyText']))

        doc.build(elements)
        pdf_bytes = buffer.getvalue()
        buffer.close()
        return pdf_bytes

    def generate_pdf_report_from_template(self, analysis: Dict[str, Any], market_data=None, charts: List[Chart] = None) -> bytes:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç PDF —Å—Ç—Ä–æ–≥–æ –ø–æ —à–∞–±–ª–æ–Ω—É templates/–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∞.md:
        - –ó–∞–ø–æ–ª–Ω—è–µ—Ç –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã —á–µ—Ä–µ–∑ generate_readable_report_from_template
        - –ü–∞—Ä—Å–∏—Ç –±–∞–∑–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã markdown (–∑–∞–≥–æ–ª–æ–≤–∫–∏, —Ü–∏—Ç–∞—Ç—ã, —Ç–∞–±–ª–∏—Ü—ã)
        - –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —à–∞–±–ª–æ–Ω–µ –∏ –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ charts
        - –û—á–∏—â–∞–µ—Ç —ç–º–æ–¥–∑–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π —à—Ä–∏—Ñ—Ç–∞
        """
        charts = charts or []
        buffer = io.BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4)

        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        from reportlab.lib.colors import HexColor
        from reportlab.platypus import Paragraph, Spacer, Table, TableStyle

        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —à—Ä–∏—Ñ—Ç—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
        try:
            font_name = None
            candidates = [
                ('/usr/share/fonts/TTF/DejaVuSans.ttf', '/usr/share/fonts/TTF/DejaVuSans-Bold.ttf'),
                ('/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', '/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf'),
                ('/usr/share/fonts/noto/NotoSans-Regular.ttf', '/usr/share/fonts/noto/NotoSans-Bold.ttf'),
                ('/usr/share/fonts/TTF/NotoSans-Regular.ttf', '/usr/share/fonts/TTF/NotoSans-Bold.ttf'),
            ]
            for regular, bold in candidates:
                try:
                    pdfmetrics.registerFont(TTFont('TemplateFont', regular))
                    pdfmetrics.registerFont(TTFont('TemplateFont-Bold', bold))
                    font_name = 'TemplateFont'
                    break
                except Exception:
                    continue
            if not font_name:
                font_name = 'Helvetica'
        except Exception:
            font_name = 'Helvetica'

        styles = getSampleStyleSheet()
        styles['Normal'].fontName = font_name
        styles['BodyText'].fontName = font_name
        styles['Heading1'].fontName = 'TemplateFont-Bold' if font_name == 'TemplateFont' else font_name
        styles['Heading2'].fontName = 'TemplateFont-Bold' if font_name == 'TemplateFont' else font_name
        styles['Title'].fontName = 'TemplateFont-Bold' if font_name == 'TemplateFont' else font_name

        heading1 = ParagraphStyle('H1', parent=styles['Heading1'], textColor=HexColor('#2E86AB'), fontSize=16, spaceAfter=10)
        heading2 = ParagraphStyle('H2', parent=styles['Heading2'], textColor=HexColor('#A23B72'), fontSize=13, spaceAfter=8)
        body = ParagraphStyle('Body', parent=styles['BodyText'], fontSize=10, spaceAfter=6)
        quote = ParagraphStyle('Quote', parent=styles['BodyText'], fontSize=10, leftIndent=12, textColor=HexColor('#555555'))

        def strip_emojis(text: str) -> str:
            # –£–¥–∞–ª—è–µ–º –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —ç–º–æ–¥–∑–∏ –∏ –Ω–µ-BMP —Å–∏–º–≤–æ–ª–æ–≤, —Å–æ—Ö—Ä–∞–Ω—è—è –∫–∏—Ä–∏–ª–ª–∏—Ü—É/–ª–∞—Ç–∏–Ω–∏—Ü—É
            try:
                import re
                return re.sub(r"[\U00010000-\U0010FFFF]", "", text)
            except Exception:
                return text

        # –ì–æ—Ç–æ–≤–∏–º —Ç–µ–∫—Å—Ç –æ—Ç—á—ë—Ç–∞
        md_text = self.generate_readable_report_from_template(analysis, market_data=market_data)
        md_text = strip_emojis(md_text)

        elements: List[Any] = []

        # –ü–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∞ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤–º–µ—Å—Ç–æ ![[...]]
        # (–≥—Ä–∞—Ñ–∏–∫–∏ –¥–æ–±–∞–≤–∏–º –≤ –∫–æ–Ω—Ü–µ –ø–µ—Ä–≤–æ–≥–æ –±–ª–æ–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏)

        lines = md_text.splitlines()

        i = 0
        while i < len(lines):
            line = lines[i].rstrip()

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            if not line:
                elements.append(Spacer(1, 6))
                i += 1
                continue

            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —à–∞–±–ª–æ–Ω–∞
            if line.strip().startswith('!['):
                i += 1
                continue

            # –ó–∞–≥–æ–ª–æ–≤–∫–∏
            if line.startswith('## '):
                elements.append(Paragraph(line[3:], heading1))
                i += 1
                continue
            if line.startswith('### '):
                elements.append(Paragraph(line[4:], heading2))
                i += 1
                continue

            # –¶–∏—Ç–∞—Ç—ã
            if line.startswith('> '):
                quote_lines = [line[2:]]
                j = i + 1
                while j < len(lines) and lines[j].startswith('> '):
                    quote_lines.append(lines[j][2:])
                    j += 1
                elements.append(Paragraph(strip_emojis(" ".join(quote_lines)), quote))
                i = j
                continue

            # –¢–∞–±–ª–∏—Ü—ã markdown
            if line.startswith('|') and line.endswith('|'):
                table_rows: List[List[str]] = []
                j = i
                while j < len(lines) and lines[j].startswith('|') and lines[j].endswith('|'):
                    row = [c.strip() for c in lines[j][1:-1].split('|')]
                    # —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å '---'
                    if not all(cell.strip('- ') == '' for cell in row):
                        table_rows.append(row)
                    j += 1
                if table_rows:
                    tbl = Table(table_rows)
                    tbl.setStyle(TableStyle([
                        ('GRID', (0, 0), (-1, -1), 0.5, colors.black),
                        ('BACKGROUND', (0, 0), (-1, 0), colors.lightgrey),
                        ('FONTNAME', (0, 0), (-1, -1), font_name),
                        ('FONTSIZE', (0, 0), (-1, -1), 9),
                    ]))
                    elements.append(tbl)
                    elements.append(Spacer(1, 8))
                i = j
                continue

            # –û–±—ã—á–Ω—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ
            elements.append(Paragraph(strip_emojis(line), body))
            i += 1

        # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –≤ –∫–æ–Ω–µ—Ü –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–∏–ª–∏ –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –º–µ—Å—Ç–æ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É)
        if charts:
            from reportlab.platypus import Image
            elements.append(Spacer(1, 12))
            elements.append(Paragraph("–ì—Ä–∞—Ñ–∏–∫–∏", heading2))
            for ch in charts:
                try:
                    img_buf = io.BytesIO(ch.image_bytes)
                    elements.append(Paragraph(strip_emojis(ch.title), body))
                    elements.append(Image(img_buf, width=500, height=250))
                    elements.append(Spacer(1, 10))
                except Exception:
                    continue

        doc.build(elements)
        pdf_bytes = buffer.getvalue()
        buffer.close()
        return pdf_bytes


